---
title: "Humanoid Parkour Learning"
collection: publications
permalink: /publications/2024-05-10-HParkour
link: https://humanoid4parkour.github.io
excerpt: 'A single vision-based end-to-end whole-body-control parkour policy for humanoid robots.
<img src="/images/humanoid-parkour-learning.png" alt="Parkour" width="500"/>'
citation: 'Zhuang, Z., Yao, S., & Zhao, H. (2024). Humanoid Parkour Learning. 8th Annual Conference on Robot Learning. '
date: 2024-05-10
venue: 'Conference on Robot Learning'
twitter: 'https://x.com/ziwenzhuang_leo/status/1788735706896138266'
---

Parkour is a grand challenge for legged locomotion, even for quadruped robots, requiring active perception and various maneuvers to overcome multiple challenging obstacles. Existing methods for humanoid locomotion either optimize a trajectory for a single parkour track or train a reinforcement learning policy only to walk with a significant amount of motion references. In this work, we propose a framework for learning an end-to-end vision-based whole-body-control parkour policy for humanoid robots that overcomes multiple parkour skills without any motion prior. Using the parkour policy, the humanoid robot can jump on a 0.42m platform, leap over hurdles, 0.8m gaps, and much more. It can also run at 1.8m/s in the wild and walk robustly on different terrains. We test our policy in indoor and outdoor environments to demonstrate that it can autonomously select parkour skills while following the rotation command of the joystick. We override the arm actions and show that this framework can easily transfer to humanoid mobile manipulation tasks.

![Parkour](/images/humanoid-parkour-learning.png)